{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyspark mllib packages are obsolete (there were used for RDD) and Pyspark.ml packages are used for new type (SQL(DATA FRAME) all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler,VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.0.0-bin-hadoop3.2\\\\'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 00:34:29 WARN Utils: Your hostname, wtc12 resolves to a loopback address: 127.0.1.1; using 10.64.26.83 instead (on interface enp3s0)\n",
      "24/09/27 00:34:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/27 00:34:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Pyspark ML Algorithms\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = spark.read.csv(\"/spark_tutorial/admission_data.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|      337|        118|                4|4.5| 4.5|9.65|       1|            0.92|\n",
      "|      324|        107|                4|  4| 4.5|8.87|       1|            0.76|\n",
      "|      316|        104|                3|  3| 3.5|   8|       1|            0.72|\n",
      "|      322|        110|                3|3.5| 2.5|8.67|       1|             0.8|\n",
      "|      314|        103|                2|  2|   3|8.21|       0|            0.65|\n",
      "|      330|        115|                5|4.5|   3|9.34|       1|             0.9|\n",
      "|      321|        109|                3|  3|   4| 8.2|       1|            0.75|\n",
      "|      308|        101|                2|  3|   4| 7.9|       0|            0.68|\n",
      "|      302|        102|                1|  2| 1.5|   8|       0|             0.5|\n",
      "|      323|        108|                3|3.5|   3| 8.6|       0|            0.45|\n",
      "|      325|        106|                3|3.5|   4| 8.4|       1|            0.52|\n",
      "|      327|        111|                4|  4| 4.5|   9|       1|            0.84|\n",
      "|      328|        112|                4|  4| 4.5| 9.1|       1|            0.78|\n",
      "|      307|        109|                3|  4|   3|   8|       1|            0.62|\n",
      "|      311|        104|                3|3.5|   2| 8.2|       1|            0.61|\n",
      "|      314|        105|                3|3.5| 2.5| 8.3|       0|            0.54|\n",
      "|      317|        107|                3|  4|   3| 8.7|       0|            0.66|\n",
      "|      319|        106|                3|  4|   3|   8|       1|            0.65|\n",
      "|      318|        110|                3|  4|   3| 8.8|       0|            0.63|\n",
      "|      303|        102|                3|3.5|   3| 8.5|       0|            0.62|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: string (nullable = true)\n",
      " |-- TOEFL Score: string (nullable = true)\n",
      " |-- University Rating: string (nullable = true)\n",
      " |-- SOP: string (nullable = true)\n",
      " |-- LOR : string (nullable = true)\n",
      " |-- CGPA: string (nullable = true)\n",
      " |-- Research: string (nullable = true)\n",
      " |-- Chance of Admit : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the coloums data types are string but in machine learning we neeed them in float or int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRE Score\n",
      "TOEFL Score\n",
      "University Rating\n",
      "SOP\n",
      "LOR \n",
      "CGPA\n",
      "Research\n",
      "Chance of Admit \n",
      "\n",
      "after applying coloumn function\n",
      "Column<'GRE Score'>\n",
      "Column<'TOEFL Score'>\n",
      "Column<'University Rating'>\n",
      "Column<'SOP'>\n",
      "Column<'LOR '>\n",
      "Column<'CGPA'>\n",
      "Column<'Research'>\n",
      "Column<'Chance of Admit '>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "for c in dataframe.columns:\n",
    "    print((c))\n",
    "print(\"\\nafter applying coloumn function\")\n",
    "for c in dataframe.columns:\n",
    "    print(col(c))    \n",
    "new_dataframe = dataframe.select(*(col(c).cast(\"float\").alias(c) for c in dataframe.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|      337|        118|                4|4.5| 4.5|9.65|       1|            0.92|\n",
      "|      324|        107|                4|  4| 4.5|8.87|       1|            0.76|\n",
      "|      316|        104|                3|  3| 3.5|   8|       1|            0.72|\n",
      "|      322|        110|                3|3.5| 2.5|8.67|       1|             0.8|\n",
      "|      314|        103|                2|  2|   3|8.21|       0|            0.65|\n",
      "|      330|        115|                5|4.5|   3|9.34|       1|             0.9|\n",
      "|      321|        109|                3|  3|   4| 8.2|       1|            0.75|\n",
      "|      308|        101|                2|  3|   4| 7.9|       0|            0.68|\n",
      "|      302|        102|                1|  2| 1.5|   8|       0|             0.5|\n",
      "|      323|        108|                3|3.5|   3| 8.6|       0|            0.45|\n",
      "|      325|        106|                3|3.5|   4| 8.4|       1|            0.52|\n",
      "|      327|        111|                4|  4| 4.5|   9|       1|            0.84|\n",
      "|      328|        112|                4|  4| 4.5| 9.1|       1|            0.78|\n",
      "|      307|        109|                3|  4|   3|   8|       1|            0.62|\n",
      "|      311|        104|                3|3.5|   2| 8.2|       1|            0.61|\n",
      "|      314|        105|                3|3.5| 2.5| 8.3|       0|            0.54|\n",
      "|      317|        107|                3|  4|   3| 8.7|       0|            0.66|\n",
      "|      319|        106|                3|  4|   3|   8|       1|            0.65|\n",
      "|      318|        110|                3|  4|   3| 8.8|       0|            0.63|\n",
      "|      303|        102|                3|3.5|   3| 8.5|       0|            0.62|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(*(col(c) for c in dataframe.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: float (nullable = true)\n",
      " |-- TOEFL Score: float (nullable = true)\n",
      " |-- University Rating: float (nullable = true)\n",
      " |-- SOP: float (nullable = true)\n",
      " |-- LOR : float (nullable = true)\n",
      " |-- CGPA: float (nullable = true)\n",
      " |-- Research: float (nullable = true)\n",
      " |-- Chance of Admit : float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(*(col(c).cast(\"float\") for c in dataframe.columns)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.select(*(col(c).cast(\"float\") for c in dataframe.columns)).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select(*[col(\"column1\"), col(\"column2\")]) is similar to select(col(\"column1\"), col(\"column2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(col('GRE Score').cast(\"float\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: float (nullable = true)\n",
      " |-- TOEFL Score: string (nullable = true)\n",
      " |-- University Rating: string (nullable = true)\n",
      " |-- SOP: string (nullable = true)\n",
      " |-- LOR : string (nullable = true)\n",
      " |-- CGPA: string (nullable = true)\n",
      " |-- Research: string (nullable = true)\n",
      " |-- Chance of Admit : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.withColumn(\"GRE Score\", col(\"GRE Score\").cast(\"float\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GRE Score: float (nullable = true)\n",
      " |-- TOEFL Score: float (nullable = true)\n",
      " |-- University Rating: float (nullable = true)\n",
      " |-- SOP: float (nullable = true)\n",
      " |-- LOR : float (nullable = true)\n",
      " |-- CGPA: float (nullable = true)\n",
      " |-- Research: float (nullable = true)\n",
      " |-- Chance of Admit : float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when #when is equivelent to where in sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRE Score\n",
      "TOEFL Score\n",
      "University Rating\n",
      "SOP\n",
      "LOR \n",
      "CGPA\n",
      "Research\n",
      "Chance of Admit \n"
     ]
    }
   ],
   "source": [
    "for c in new_dataframe.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|    337.0|      118.0|              4.0|4.5| 4.5|9.65|     1.0|            0.92|\n",
      "|    324.0|      107.0|              4.0|4.0| 4.5|8.87|     1.0|            0.76|\n",
      "|    316.0|      104.0|              3.0|3.0| 3.5| 8.0|     1.0|            0.72|\n",
      "|    322.0|      110.0|              3.0|3.5| 2.5|8.67|     1.0|             0.8|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_dataframe.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|        0|          0|                0|  0|   0|   0|       0|               0|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for null ir nan type values in our columns\n",
    "new_dataframe.select([count(when(col(c).isNull(), c)).alias(c) for c in new_dataframe.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------------------------------------+-------------------------------------------+---------------------------------------------+---------------------------------------------+-----------------------------------------------------+---------------------------------------------------------------------+\n",
      "|count(CASE WHEN (GRE Score IS NULL) THEN GRE Score END)|count(CASE WHEN (TOEFL Score IS NULL) THEN TOEFL Score END)|count(CASE WHEN (University Rating IS NULL) THEN University Rating END)|count(CASE WHEN (SOP IS NULL) THEN SOP END)|count(CASE WHEN (LOR  IS NULL) THEN LOR  END)|count(CASE WHEN (CGPA IS NULL) THEN CGPA END)|count(CASE WHEN (Research IS NULL) THEN Research END)|count(CASE WHEN (Chance of Admit  IS NULL) THEN Chance of Admit  END)|\n",
      "+-------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------------------------------------+-------------------------------------------+---------------------------------------------+---------------------------------------------+-----------------------------------------------------+---------------------------------------------------------------------+\n",
      "|                                                      0|                                                          0|                                                                      0|                                          0|                                            0|                                            0|                                                    0|                                                                    0|\n",
      "+-------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------------------------------------+-------------------------------------------+---------------------------------------------+---------------------------------------------+-----------------------------------------------------+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for null ir nan type values in our columns\n",
    "new_dataframe.select([ count (when (col (c).isNull(), c) ) for c in new_dataframe.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(inputCols=[\"GRE Score\", \"TOEFL Score\",\"University Rating\"], \n",
    "                  outputCols=[\"GRE Score\", \"TOEFL Score\",\"University Rating\"])\n",
    "model = imputer.fit(new_dataframe)\n",
    "\n",
    "imputed_data = model.transform(new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[GRE Score: float, TOEFL Score: float, University Rating: float, SOP: float, LOR : float, CGPA: float, Research: float, Chance of Admit : float]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "|        0|          0|                0|  0|   0|   0|       0|               0|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for null ir nan type values in our columns\n",
    "imputed_data.select([count(when(col(c).isNull(), c)).alias(c) for c in imputed_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = imputed_data.drop('Chance of Admit ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GRE Score',\n",
       " 'TOEFL Score',\n",
       " 'University Rating',\n",
       " 'SOP',\n",
       " 'LOR ',\n",
       " 'CGPA',\n",
       " 'Research']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assemble our features together using vectorAssembler\n",
    "\n",
    "\n",
    "# it will take all columns and combine them like a vector (1,3,4,5)\n",
    "\n",
    "assembler = VectorAssembler( inputCols=features.columns,outputCol=\"features\")\n",
    "\n",
    "#we have created new coloumn features where we will have our vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------------+---+----+----+--------+----------------+--------------------+\n",
      "|GRE Score|TOEFL Score|University Rating|SOP|LOR |CGPA|Research|Chance of Admit |            features|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+--------------------+\n",
      "|    337.0|      118.0|              4.0|4.5| 4.5|9.65|     1.0|            0.92|[337.0,118.0,4.0,...|\n",
      "|    324.0|      107.0|              4.0|4.0| 4.5|8.87|     1.0|            0.76|[324.0,107.0,4.0,...|\n",
      "|    316.0|      104.0|              3.0|3.0| 3.5| 8.0|     1.0|            0.72|[316.0,104.0,3.0,...|\n",
      "|    322.0|      110.0|              3.0|3.5| 2.5|8.67|     1.0|             0.8|[322.0,110.0,3.0,...|\n",
      "|    314.0|      103.0|              2.0|2.0| 3.0|8.21|     0.0|            0.65|[314.0,103.0,2.0,...|\n",
      "|    330.0|      115.0|              5.0|4.5| 3.0|9.34|     1.0|             0.9|[330.0,115.0,5.0,...|\n",
      "|    321.0|      109.0|              3.0|3.0| 4.0| 8.2|     1.0|            0.75|[321.0,109.0,3.0,...|\n",
      "|    308.0|      101.0|              2.0|3.0| 4.0| 7.9|     0.0|            0.68|[308.0,101.0,2.0,...|\n",
      "|    302.0|      102.0|              1.0|2.0| 1.5| 8.0|     0.0|             0.5|[302.0,102.0,1.0,...|\n",
      "|    323.0|      108.0|              3.0|3.5| 3.0| 8.6|     0.0|            0.45|[323.0,108.0,3.0,...|\n",
      "|    325.0|      106.0|              3.0|3.5| 4.0| 8.4|     1.0|            0.52|[325.0,106.0,3.0,...|\n",
      "|    327.0|      111.0|              4.0|4.0| 4.5| 9.0|     1.0|            0.84|[327.0,111.0,4.0,...|\n",
      "|    328.0|      112.0|              4.0|4.0| 4.5| 9.1|     1.0|            0.78|[328.0,112.0,4.0,...|\n",
      "|    307.0|      109.0|              3.0|4.0| 3.0| 8.0|     1.0|            0.62|[307.0,109.0,3.0,...|\n",
      "|    311.0|      104.0|              3.0|3.5| 2.0| 8.2|     1.0|            0.61|[311.0,104.0,3.0,...|\n",
      "|    314.0|      105.0|              3.0|3.5| 2.5| 8.3|     0.0|            0.54|[314.0,105.0,3.0,...|\n",
      "|    317.0|      107.0|              3.0|4.0| 3.0| 8.7|     0.0|            0.66|[317.0,107.0,3.0,...|\n",
      "|    319.0|      106.0|              3.0|4.0| 3.0| 8.0|     1.0|            0.65|[319.0,106.0,3.0,...|\n",
      "|    318.0|      110.0|              3.0|4.0| 3.0| 8.8|     0.0|            0.63|[318.0,110.0,3.0,...|\n",
      "|    303.0|      102.0|              3.0|3.5| 3.0| 8.5|     0.0|            0.62|[303.0,102.0,3.0,...|\n",
      "+---------+-----------+-----------------+---+----+----+--------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[337.0, 118.0, 4.0, 4.5, 4.5, 9.64999961853027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[324.0, 107.0, 4.0, 4.0, 4.5, 8.86999988555908...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[316.0, 104.0, 3.0, 3.0, 3.5, 8.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[322.0, 110.0, 3.0, 3.5, 2.5, 8.67000007629394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[314.0, 103.0, 2.0, 2.0, 3.0, 8.21000003814697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[332.0, 108.0, 5.0, 4.5, 4.0, 9.02000045776367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[337.0, 117.0, 5.0, 5.0, 5.0, 9.86999988555908...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[330.0, 120.0, 5.0, 4.5, 5.0, 9.5600004196167,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[312.0, 103.0, 4.0, 4.0, 5.0, 8.43000030517578...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[327.0, 113.0, 4.0, 4.5, 4.5, 9.03999996185302...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              features\n",
       "0    [337.0, 118.0, 4.0, 4.5, 4.5, 9.64999961853027...\n",
       "1    [324.0, 107.0, 4.0, 4.0, 4.5, 8.86999988555908...\n",
       "2              [316.0, 104.0, 3.0, 3.0, 3.5, 8.0, 1.0]\n",
       "3    [322.0, 110.0, 3.0, 3.5, 2.5, 8.67000007629394...\n",
       "4    [314.0, 103.0, 2.0, 2.0, 3.0, 8.21000003814697...\n",
       "..                                                 ...\n",
       "495  [332.0, 108.0, 5.0, 4.5, 4.0, 9.02000045776367...\n",
       "496  [337.0, 117.0, 5.0, 5.0, 5.0, 9.86999988555908...\n",
       "497  [330.0, 120.0, 5.0, 4.5, 5.0, 9.5600004196167,...\n",
       "498  [312.0, 103.0, 4.0, 4.0, 5.0, 8.43000030517578...\n",
       "499  [327.0, 113.0, 4.0, 4.5, 4.5, 9.03999996185302...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.select(\"features\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= output.select(\"features\", \"Chance of Admit \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= output.select(\"features\", \"Chance of Admit \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = output.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|            features|Chance of Admit |\n",
      "+--------------------+----------------+\n",
      "|[290.0,100.0,1.0,...|            0.47|\n",
      "|[290.0,104.0,4.0,...|            0.45|\n",
      "|[293.0,97.0,2.0,2...|            0.64|\n",
      "|[294.0,93.0,1.0,1...|            0.46|\n",
      "|[294.0,95.0,1.0,1...|            0.49|\n",
      "|[295.0,93.0,1.0,2...|            0.46|\n",
      "|[295.0,96.0,2.0,1...|            0.47|\n",
      "|[295.0,99.0,2.0,2...|            0.57|\n",
      "|[296.0,99.0,2.0,3...|            0.47|\n",
      "|[296.0,101.0,1.0,...|             0.6|\n",
      "|[297.0,96.0,2.0,2...|            0.43|\n",
      "|[297.0,96.0,2.0,2...|            0.34|\n",
      "|[297.0,98.0,2.0,2...|            0.59|\n",
      "|[297.0,99.0,4.0,3...|            0.54|\n",
      "|[297.0,101.0,3.0,...|            0.57|\n",
      "|[298.0,92.0,1.0,2...|            0.51|\n",
      "|[298.0,97.0,2.0,2...|            0.45|\n",
      "|[298.0,98.0,2.0,1...|            0.44|\n",
      "|[298.0,99.0,1.0,1...|            0.53|\n",
      "|[298.0,99.0,2.0,4...|            0.46|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+----------------+\n",
      "|            features|Chance of Admit |\n",
      "+--------------------+----------------+\n",
      "|[295.0,99.0,1.0,2...|            0.37|\n",
      "|[295.0,101.0,2.0,...|            0.69|\n",
      "|[296.0,95.0,2.0,3...|            0.44|\n",
      "|[296.0,97.0,2.0,1...|            0.49|\n",
      "|[296.0,99.0,2.0,2...|            0.61|\n",
      "|[297.0,100.0,1.0,...|            0.52|\n",
      "|[298.0,98.0,2.0,4...|            0.34|\n",
      "|[298.0,100.0,3.0,...|            0.58|\n",
      "|[298.0,101.0,2.0,...|            0.54|\n",
      "|[299.0,100.0,1.0,...|            0.59|\n",
      "|[299.0,100.0,2.0,...|            0.51|\n",
      "|[299.0,100.0,2.0,...|            0.68|\n",
      "|[299.0,100.0,3.0,...|            0.63|\n",
      "|[299.0,106.0,2.0,...|            0.64|\n",
      "|[300.0,100.0,3.0,...|            0.64|\n",
      "|[300.0,102.0,2.0,...|            0.56|\n",
      "|[300.0,104.0,3.0,...|            0.71|\n",
      "|[300.0,105.0,1.0,...|            0.58|\n",
      "|[301.0,96.0,1.0,3...|            0.54|\n",
      "|[301.0,98.0,1.0,2...|            0.67|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 01:20:14 WARN Instrumentation: [b928f2aa] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression(featuresCol = 'features', labelCol='Chance of Admit ')\n",
    "linear_model = lin_reg.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.002340622269278282,0.0026498371025821667,0.004969790477750323,0.003191139828103571,0.01654263680641741,0.11710541247885004,0.01645541680556034]\n",
      "Intercept: -1.4007993988530205\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(linear_model.coefficients))\n",
    "print(\"Intercept: \" + str(linear_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.059427\n",
      "r2: 0.827019\n"
     ]
    }
   ],
   "source": [
    "trainSummary = linear_model.summary\n",
    "print(\"RMSE: %f\" % trainSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+--------------------+\n",
      "|        prediction|Chance of Admit |            features|\n",
      "+------------------+----------------+--------------------+\n",
      "|0.4746720616506619|            0.37|[295.0,99.0,1.0,2...|\n",
      "|0.5287689798024866|            0.69|[295.0,101.0,2.0,...|\n",
      "|0.4957878140801757|            0.44|[296.0,95.0,2.0,3...|\n",
      "|0.5102927957854271|            0.49|[296.0,97.0,2.0,1...|\n",
      "|0.5539891194854356|            0.61|[296.0,99.0,2.0,2...|\n",
      "|0.5273236689645442|            0.52|[297.0,100.0,1.0,...|\n",
      "|0.5690785550667741|            0.34|[298.0,98.0,2.0,4...|\n",
      "|0.5981909395556371|            0.58|[298.0,100.0,3.0,...|\n",
      "|0.5325997067822177|            0.54|[298.0,101.0,2.0,...|\n",
      "|0.5308338325750104|            0.59|[299.0,100.0,1.0,...|\n",
      "|0.5362281678789342|            0.51|[299.0,100.0,2.0,...|\n",
      "| 0.564233262916664|            0.68|[299.0,100.0,2.0,...|\n",
      "|0.5575927563086762|            0.63|[299.0,100.0,3.0,...|\n",
      "| 0.652489500178651|            0.64|[299.0,106.0,2.0,...|\n",
      "|0.6678788247009249|            0.64|[300.0,100.0,3.0,...|\n",
      "|0.5411018135112347|            0.56|[300.0,102.0,2.0,...|\n",
      "|0.6082567598084236|            0.71|[300.0,104.0,3.0,...|\n",
      "|0.5342886212913955|            0.58|[300.0,105.0,1.0,...|\n",
      "| 0.524142934874642|            0.54|[301.0,96.0,1.0,3...|\n",
      "|0.5812037685462119|            0.67|[301.0,98.0,1.0,2...|\n",
      "+------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "predictions = linear_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"Chance of Admit \",\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.807457579521907\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "pred_evaluator = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"Chance of Admit \",metricName='r2')\n",
    "print(\"R Squared (R2) on test data =\", pred_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.807457579521907\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "pred_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Chance of Admit \",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data =\", pred_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer = featureIndexer.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|     indexedFeatures|Chance of Admit |\n",
      "+--------------------+----------------+\n",
      "|[337.0,118.0,4.0,...|            0.92|\n",
      "|[324.0,107.0,4.0,...|            0.76|\n",
      "|[316.0,104.0,3.0,...|            0.72|\n",
      "|[322.0,110.0,3.0,...|             0.8|\n",
      "|[314.0,103.0,2.0,...|            0.65|\n",
      "|[330.0,115.0,5.0,...|             0.9|\n",
      "|[321.0,109.0,3.0,...|            0.75|\n",
      "|[308.0,101.0,2.0,...|            0.68|\n",
      "|[302.0,102.0,1.0,...|             0.5|\n",
      "|[323.0,108.0,3.0,...|            0.45|\n",
      "|[325.0,106.0,3.0,...|            0.52|\n",
      "|[327.0,111.0,4.0,...|            0.84|\n",
      "|[328.0,112.0,4.0,...|            0.78|\n",
      "|[307.0,109.0,3.0,...|            0.62|\n",
      "|[311.0,104.0,3.0,...|            0.61|\n",
      "|[314.0,105.0,3.0,...|            0.54|\n",
      "|[317.0,107.0,3.0,...|            0.66|\n",
      "|[319.0,106.0,3.0,...|            0.65|\n",
      "|[318.0,110.0,3.0,...|            0.63|\n",
      "|[303.0,102.0,3.0,...|            0.62|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_indexed_data = featureIndexer.select(\"indexedFeatures\", \"Chance of Admit \")\n",
    "new_indexed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = new_indexed_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|     indexedFeatures|Chance of Admit |\n",
      "+--------------------+----------------+\n",
      "|[290.0,100.0,1.0,...|            0.47|\n",
      "|[290.0,104.0,4.0,...|            0.45|\n",
      "|[293.0,97.0,2.0,2...|            0.64|\n",
      "|[294.0,93.0,1.0,1...|            0.46|\n",
      "|[294.0,95.0,1.0,1...|            0.49|\n",
      "|[295.0,93.0,1.0,2...|            0.46|\n",
      "|[295.0,99.0,1.0,2...|            0.37|\n",
      "|[295.0,99.0,2.0,2...|            0.57|\n",
      "|[295.0,101.0,2.0,...|            0.69|\n",
      "|[296.0,95.0,2.0,3...|            0.44|\n",
      "|[296.0,99.0,2.0,2...|            0.61|\n",
      "|[296.0,99.0,2.0,3...|            0.47|\n",
      "|[296.0,101.0,1.0,...|             0.6|\n",
      "|[297.0,96.0,2.0,2...|            0.34|\n",
      "|[297.0,100.0,1.0,...|            0.52|\n",
      "|[297.0,101.0,3.0,...|            0.57|\n",
      "|[298.0,97.0,2.0,2...|            0.45|\n",
      "|[298.0,98.0,2.0,4...|            0.34|\n",
      "|[298.0,99.0,1.0,1...|            0.53|\n",
      "|[298.0,101.0,2.0,...|            0.54|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|     indexedFeatures|Chance of Admit |\n",
      "+--------------------+----------------+\n",
      "|[295.0,96.0,2.0,1...|            0.47|\n",
      "|[296.0,97.0,2.0,1...|            0.49|\n",
      "|[297.0,96.0,2.0,2...|            0.43|\n",
      "|[297.0,98.0,2.0,2...|            0.59|\n",
      "|[297.0,99.0,4.0,3...|            0.54|\n",
      "|[298.0,92.0,1.0,2...|            0.51|\n",
      "|[298.0,98.0,2.0,1...|            0.44|\n",
      "|[298.0,99.0,2.0,4...|            0.46|\n",
      "|[298.0,100.0,3.0,...|            0.58|\n",
      "|[298.0,105.0,3.0,...|            0.69|\n",
      "|[299.0,94.0,1.0,1...|            0.42|\n",
      "|[299.0,97.0,3.0,5...|            0.38|\n",
      "|[300.0,99.0,1.0,1...|            0.58|\n",
      "|[300.0,100.0,3.0,...|            0.62|\n",
      "|[300.0,102.0,3.0,...|            0.63|\n",
      "|[301.0,99.0,2.0,3...|            0.64|\n",
      "|[301.0,104.0,3.0,...|            0.68|\n",
      "|[301.0,106.0,4.0,...|            0.57|\n",
      "|[302.0,102.0,1.0,...|             0.5|\n",
      "|[302.0,102.0,3.0,...|            0.65|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor(featuresCol=\"indexedFeatures\",labelCol=\"Chance of Admit \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexer.\n",
    "model = random_forest_reg.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------------+\n",
      "|     indexedFeatures|Chance of Admit |         prediction|\n",
      "+--------------------+----------------+-------------------+\n",
      "|[295.0,96.0,2.0,1...|            0.47| 0.4590550186660273|\n",
      "|[296.0,97.0,2.0,1...|            0.49| 0.5254360635158737|\n",
      "|[297.0,96.0,2.0,2...|            0.43|  0.540430705120381|\n",
      "|[297.0,98.0,2.0,2...|            0.59| 0.5199240121945102|\n",
      "|[297.0,99.0,4.0,3...|            0.54|  0.567643205682866|\n",
      "|[298.0,92.0,1.0,2...|            0.51| 0.5343580769164088|\n",
      "|[298.0,98.0,2.0,1...|            0.44|0.49678202877990224|\n",
      "|[298.0,99.0,2.0,4...|            0.46| 0.4231837493293322|\n",
      "|[298.0,100.0,3.0,...|            0.58| 0.5959031817536276|\n",
      "|[298.0,105.0,3.0,...|            0.69| 0.6747937840090809|\n",
      "|[299.0,94.0,1.0,1...|            0.42| 0.4802391547768181|\n",
      "|[299.0,97.0,3.0,5...|            0.38| 0.5472979043487081|\n",
      "|[300.0,99.0,1.0,1...|            0.58|  0.564282028304626|\n",
      "|[300.0,100.0,3.0,...|            0.62| 0.6303783351830613|\n",
      "|[300.0,102.0,3.0,...|            0.63| 0.6497041247361841|\n",
      "|[301.0,99.0,2.0,3...|            0.64| 0.6138733968320848|\n",
      "|[301.0,104.0,3.0,...|            0.68| 0.6601313414150634|\n",
      "|[301.0,106.0,4.0,...|            0.57| 0.6519913248194906|\n",
      "|[302.0,102.0,1.0,...|             0.5|  0.561731584182484|\n",
      "|[302.0,102.0,3.0,...|            0.65| 0.6560621537117183|\n",
      "+--------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data =  0.052713483049392995\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Chance of Admit \", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "print (\"Root Mean Squared Error (RMSE) on test data = \",evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.8642616003425612\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Chance of Admit \", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data =\", evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor(featuresCol=\"features\",labelCol=\"Chance of Admit \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexer.\n",
    "model = random_forest_reg.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data =  0.06359511707471763\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Chance of Admit \", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "print (\"Root Mean Squared Error (RMSE) on test data = \",evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.784325199165696\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Chance of Admit \", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data =\", evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
